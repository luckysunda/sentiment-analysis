# E0 334 Assignment 1

In this assignment, you are tasked with implementing a preprocessing and classification pipeline for 3 datasets, namely:

1. The [Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/) (IMDB).
2. The [Stanford Natural Language Inference Corpus](https://nlp.stanford.edu/projects/snli/) (SNLI).
3. [AG's News Topic Classification Dataset](https://github.com/mhjabreel/CharCNN/tree/master/data/ag_news_csv).

For the purposes of this assignment, you are only allowed to use `Bag of Words` and `Bag of N-Grams`-based representations. You may make use of any classifier.

## Getting Started

Please start by cloning this repository, and edit the three Python files to implement your solution. In case you are using Python 3, please update the Shebang (`#!`)  to reflect this.

## Submission Instructions

In your submission, update a `readme.md` file that includes the list of all packages that must be installed for your solution. Detail your results on the validation set, strategy for feature selection and any ablation studies you might have performed separately in a `report.pdf` file. It should be possible to run your code on a fresh virtualenv after installing the specified packages without any other set-up. We will install the specified packages, and then run the three Python scripts to check your solution.

To submit your solution, go to `Settings > User and group access` and add `sohampal@iisc.ac.in` with `Read` access to the `Users` section. We will automatically retreieve the latest submission via git.
